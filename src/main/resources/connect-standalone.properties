bootstrap.servers = ${KAFKA_BROKERS}
key.converter = org.apache.kafka.connect.json.JsonConverter
value.converter = org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable = true
value.converter.schemas.enable = true
internal.key.converter = org.apache.kafka.connect.json.JsonConverter
internal.value.converter = org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable = false
internal.value.converter.schemas.enable = false
offset.storage.file.filename = ${SOURCE_OFFSET}
rest.port = 8082
offset.flush.interval.ms = 60000
consumer.sasl.kerberos.kinit.cmd = ${KINIT_COMMAND}
consumer.security.protocol = PLAINTEXTSASL
consumer.sasl.kerberos.service.name = kafka
producer.sasl.kerberos.kinit.cmd = ${KINIT_COMMAND}
producer.security.protocol = PLAINTEXTSASL
producer.sasl.kerberos.service.name = kafka